bcp文件入库：
1.bcp文件放到/home/bcpsplit/dam_inpath目录下，等待切分程序切分。
2.切分后的bcp被转移到/home/bcpsplit/dam_outpath下对应的主机目录中。
3.dataloader启动后会有两个进程dataloader.py、statloader.py，可以ps -ef | grep loader查看
4.dataloader.py读取/home/bcpsplit/dam_outpath下对应主机目录中的bcp，调用sqlldr入库；
在sqlldr日志暂时存放在/home/noah/dataloader/log/log，如果此类bcp的要生成统计信息，则入库结束后日志文件被移到/home/noah/dataloader/log/stat/log目录中，否则删除；
如果入库没有完全成功，则入库日志会被备份到/home/noah/dataloader/log/bad目录中，对应的bcp错误文件也会备份到/home/noah/dataloader/bad目录中；
入库结束，dataloader.py将入库状态等写入到/home/noah/dataloader/log/sys/${主机目录}_${线程名}.log文件中。
5.要确保每一种bcp都能入库，其中包括dataloader生成的统计bcp。

解析sqlldr日志，生成统计bcp：
1.statloader.py读取/home/noah/dataloader/log/stat/log目录中sqlldr日志，生成统计bcp文件。
2.统计bcp文件暂时被放到/home/noah/dataloader/log/stat/bcp。
3.统计bcp文件生成结束，则会被移动到/home/bcpsplit/dam_outpath/${平台库主机目录}目录中，文件名为DATANUM_TB_*_*（如果平台库与基础库在同一台机器，则也可能入到基础库表中，可参考etc/dbn.cfg文件中的local_dbid的值）。
4.统计bcp被dataloader.py读取入库。
5.要确保统计数据能生成，并且入库成功，入库表名为DATANUM_TB。

删除过期文件：
1./etc/cron.d/cleaner_cron每天2：30执行一次，删除过期日志文件。
2.过期时间由cleaner.sh脚本中的dura变量决定，默认为7天，即保留七天的数据（不包括今天）。
3.要确保过期数据会被删除。

dataloader系统日志
1.系统日志目录/home/noah/dataloader/log/sys。
2.dataloader.log为dataloader主程序生成的日志，主要是记录了对目录的检查结果，及每次启动线程和等待等信息。
3.主机目录_线程名.log为每个线程的日志，其中记录了sqlldr生成的日志名、控制文件名、成功条数、失败条数、入库状态等。
4.statloader.log记录了统计bcp生成情况。
5.每类日志的历史文件都会有一个YYYY-MM-DD的后缀，如今天是2012-09-22，今天的日志文件为dataloader.log，昨天的同类日志则为dataloader.log.2012-09-21。